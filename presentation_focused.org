#+TITLE: The Hunt for 49% Overhead: A Matrix Multiplication Detective Story
#+AUTHOR: Olav
#+DATE: 2025-11-05
#+STARTUP: overview
#+OPTIONS: toc:nil num:nil

* The Mystery

I optimized my matrix multiplication code with every trick I knew:
- âœ… Cache blocking for L1 locality
- âœ… SIMD vectorization (AVX2)
- âœ… Column-major memory layout

*Result*: 7.7Ã— faster than naive... but still felt slow.

*Something was wrong.*

* What is Matrix Multiplication?

Quick reminder:

#+BEGIN_SRC rust
// Square n*n matrices
for i in 0..n {
    for j in 0..n {
        for k in 0..n {
            c[i][j] += a[i][k] * b[k][j];
        }
    }
}
#+END_SRC

*The problem*: ~b[k][j]~ jumps around memory (cache misses!)

For 512Ã—512 matrices: *268 million operations*

* The Naive Baseline

512Ã—512 matrices:
- L1 cache miss rate: *~48%* ðŸ’¥
- Performance: Very slow (baseline)

Nearly half of all memory accesses miss L1 cache!

* Optimization #1: Cache Blocking

Split into 64Ã—64 blocks (fits in L1d cache: 37KB)

#+BEGIN_SRC rust
// 6-nested loop algorithm
for ii in (0..n).step_by(64) {
    for jj in (0..n).step_by(64) {
        for kk in (0..n).step_by(64) {
            // Process 64Ã—64 sub-blocks
            for i in ii..(ii+64) {
                for j in jj..(jj+64) {
                    for k in kk..(kk+64) {
                        c[i][j] += a[i][k] * b[k][j];
                    }
                }
            }
        }
    }
}
#+END_SRC

*Result*: *~3-4Ã— speedup*

But L1 miss rate still ~46%... ðŸ¤”

* Optimization #2: SIMD Vectorization

AVX2: Process 4Ã— f64 values in parallel

#+BEGIN_SRC rust
unsafe fn simd_dotprod_avx2(a: &[f64], b: &[f64]) -> f64 {
    let mut sum_vec = _mm256_setzero_pd();
    for i in (0..len).step_by(4) {
        let a_vec = _mm256_loadu_pd(a.as_ptr().add(i));
        let b_vec = _mm256_loadu_pd(b.as_ptr().add(i));
        sum_vec = _mm256_add_pd(sum_vec, _mm256_mul_pd(a_vec, b_vec));
    }
    // Sum 4 elements + handle remainder
}
#+END_SRC

*Result*: *~7-8Ã— total speedup*

L1 miss rate: ~8% (much better!)

* The Nagging Feeling

7-8Ã— speedup sounds great... but:
- nalgebra (production library): Very fast
- Our SIMD code: Still felt slow
- Gap: *Several times slower*

And I couldn't shake the feeling something was wasteful.

*Time to profile properly.*

* The Smoking Gun: perf stat

#+BEGIN_SRC sh
perf stat -d ./matmul_simd
#+END_SRC

Key metric revealed:
- *Backend Bound: ~49%*

*Nearly half of execution time stalled... why?*

* Deep Dive: perf record

#+BEGIN_SRC sh
perf record -g ./matmul_simd
perf report
#+END_SRC

Hotspot: ~fill_col_buf()~ consuming 49% of samples

*Wait... why is column buffer filling so expensive?*

* The Bug

#+BEGIN_SRC rust
// BUGGY CODE
for i in ii..i_end {               // 64 iterations
    fill_row_buf(i);               // Load A row: 64 elements
    for j in jj..j_end {           // 64 iterations
        fill_col_buf(j);           // â† LOADED 64 TIMES!
        dotprod(row_buf, col_buf); // 64 elements
    }
}
#+END_SRC

*Column buffer filled once per (i,j) pair instead of once per j!*

- Should fill: 64 column buffers (once each)
- Actually filled: 64 Ã— 64 = *4,096 times*

Per 64Ã—64 block: 262,144 redundant fills!

* The Fix

#+BEGIN_SRC rust
// FIXED CODE
// Pre-fill ALL column buffers once per j-block
let col_bufs = prefill_all_columns(jj..j_end);  // 64 buffers

for i in ii..i_end {
    fill_row_buf(i);
    for j in jj..j_end {
        let col_buf = &col_bufs[j - jj];  // â† REUSE!
        dotprod(row_buf, col_buf);
    }
}
#+END_SRC

Simple change: hoist column buffer prep outside inner loop.

* The Results

512Ã—512 matrices:

| Implementation | L1 Miss Rate | Speedup vs Naive |
|----------------|--------------|------------------|
| Naive | ~48% ðŸ’¥ | 1.0Ã— |
| Blocked | ~46% | ~3-4Ã— |
| SIMD | ~8% | ~7-8Ã— |
| *Fixed* | *~2%* âœ… | *~10-15Ã—* |
| nalgebra | ~3% | ~50Ã—+ |

*~2Ã— additional speedup from one algorithmic fix!*

After fixing buffer reuse:
- Instructions: ~2.8Ã— fewer
- L1 misses: ~4-5Ã— better
- Backend bound: 49% â†’ ~21%

* What Didn't Work

Before profiling, we tried *FMA* (fused multiply-add):

#+BEGIN_SRC rust
// Instead of separate multiply + add
sum_vec = _mm256_add_pd(sum_vec, _mm256_mul_pd(a_vec, b_vec));

// Use single FMA instruction
sum_vec = _mm256_fmadd_pd(a_vec, b_vec, sum_vec);
#+END_SRC

*Result*: *0% improvement!*

*Why?* Not bottlenecked by arithmetic. Real problem was algorithmic.

* Lessons Learned

1. *Profile first, optimize second*
   - FMA: 0% gain (guessing)
   - Buffer reuse: 130% gain (profiling)

2. *Hardware counters tell the truth*
   - "Backend Bound: 49%" = find where CPU stalls
   - L1 miss rate = memory access patterns

3. *Algorithmic > Instruction-level*
   - Fancy SIMD intrinsics: useful but not magic
   - Removing redundant work: always wins

4. *Good intuition comes from measurement*
   - "Felt slow" â†’ profiling â†’ found 49% waste
   - Trust your gut, but verify with data

* The Gap Remains

We're still *several times slower* than nalgebra.

*Why?*
- They do *far fewer L1 loads* (better algorithms)
- Register tiling (keep 4Ã—4 blocks in CPU registers)
- Micro-kernels (no intermediate buffers)
- Matrix packing (optimize layout once)

*But*: Our dot product *beats* nalgebra: 271ns vs 288ns!

Sometimes you win the battle but not the war.

*Note*: Exact performance varies by hardware/compiler.

* Key Takeaway

#+BEGIN_QUOTE
*"Don't guess. Profile first, then optimize what actually matters."*

The 49% overhead was invisible without ~perf~.
FMA seemed promising but gave 0%.
The real win came from understanding the bottleneck.
#+END_QUOTE

* Code & Resources

GitHub: https://github.com/yourusername/matmul (replace with actual)

Key files:
- ~src/implementations.rs~ - naive â†’ blocked â†’ SIMD â†’ optimized
- ~src/dotprod.rs~ - dot product variants
- ~compare_perf.sh~ - perf profiling script

Try it yourself:
#+BEGIN_SRC sh
cargo +nightly bench
./compare_perf.sh 512 cache
#+END_SRC

* Questions?

Happy to discuss:
- Cache optimization techniques
- SIMD programming
- Performance profiling workflows
- Why nalgebra is still 3Ã— faster!
